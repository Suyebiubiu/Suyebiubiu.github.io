<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>大数据学习之路</title>
      <link href="/2021/04/22/da-shu-ju-xue-xi-zhi-lu/"/>
      <url>/2021/04/22/da-shu-ju-xue-xi-zhi-lu/</url>
      
        <content type="html"><![CDATA[<h1 id="0-写在前面"><a href="#0-写在前面" class="headerlink" title="0.写在前面"></a>0.写在前面</h1><p>​这个系列记录了自己在大数据方向的学习历程，大致包含几个方面，第一部分是linux和高并发基础知识；第二部分是Hadoop体系相关内容，包括hdfs、MapReduce、hive、hbase和ZK等多个知识模块；第三部分是Spark体系相关知识，包括scala、spark-core、spark-sql、spark-stream和storm等知识模块；第四部分是Flink实时计算相关，包括了Flink基础、Flink SQL和Flink CDC等相关知识；第五部分是数据库相关知识，比如Nosql中的redis，ES等；第六部分是消息队列MQ相关，包括kafka、RocketMQ等；第七部分是数据同步相关；第八部分工作流调度相关。</p><h1 id="1-linux和高并发基本知识"><a href="#1-linux和高并发基本知识" class="headerlink" title="1.linux和高并发基本知识"></a>1.linux和高并发基本知识</h1><h2 id="1-1-linux操作系统"><a href="#1-1-linux操作系统" class="headerlink" title="1.1 linux操作系统"></a>1.1 linux操作系统</h2><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/104340503">1.1.1 linux和高并发-linux操作系统-linux虚拟机的安装</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/104340730">1.1.2 linux和高并发-linux操作系统-linux网络配置</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/104343410">1.1.3 linux和高并发-linux操作系统-linux简单命令学习</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/104353518">1.1.4 linux和高并发-linux操作系统-linux文件系统</a></p><h2 id="1-2-linux基本命令"><a href="#1-2-linux基本命令" class="headerlink" title="1.2 linux基本命令"></a>1.2 linux基本命令</h2><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/104369270">1.2.1 linux和高并发-linux基本命令-linux文件系统命令</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/104382647">1.2.2 linux和高并发-linux基本命令-vi全屏文本编辑器</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/104394706">1.2.3 linux和高并发-linux基本命令-正则表达式</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/104405023">1.2.4 linux和高并发-linux基本命令-文本分析</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/104426123">1.2.5 linux和高并发-linux基本命令-linux用户与权限</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/122309784">1.2.6 linux和高并发-linux基本命令-linux环境变量配置说明</a></p><h2 id="1-3-linux软件安装"><a href="#1-3-linux软件安装" class="headerlink" title="1.3 linux软件安装"></a>1.3 linux软件安装</h2><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/104440497">1.3.1 linux和高并发-linux软件安装-linux编译安装</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/104458582">1.3.2 linux和高并发-linux软件安装-rpm软件安装</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/104475811">1.3.3 linux和高并发-linux软件安装-yum安装及配置</a></p><h2 id="1-4-shell编程"><a href="#1-4-shell编程" class="headerlink" title="1.4 shell编程"></a>1.4 shell编程</h2><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/104494798">1.4.1 linux和高并发-shell编程-bash</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/104496290">1.4.2 linux和高并发-shell编程-文本流及重定向</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/104515761">1.4.3 linux和高并发-shell编程-变量</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/104576809">1.4.4 linux和高并发-shell编程-引用和逻辑判断</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/105200796">1.4.5 linux和高并发-shell编程-表达式（算术表达式+条件表达式）</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/105218658">1.4.6 linux和高并发-shell编程-添加用户脚本</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/105227789">1.4.7 linux和高并发-shell编程-流程控制</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/105229263">1.4.8 linux和高并发-shell编程-shell脚本编程总结</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109239104">1.4.9 linux和高并发-shell编程-shell分发脚本</a></p><p><a href="https://blank.blog.csdn.net/article/details/109313264">1.4.10 linux和高并发-shell编程-Zookeeper启动脚本（启动，停止，查看状态）</a></p><p><a href="https://blank.blog.csdn.net/article/details/111533963">1.4.11 linux和高并发-shell编程-查看集群进程脚本</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/111534604">1.4.12 linux和高并发-shell编程-ha-hadoop脚本编写</a></p><h2 id="1-5-网络基础知识"><a href="#1-5-网络基础知识" class="headerlink" title="1.5 网络基础知识"></a>1.5 网络基础知识</h2><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/105232500">1.5.1 linux和高并发-网络基础知识-高并发与负载均衡之理论</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/105233003">1.5.2 linux和高并发-网络基础知识-网络TCP/IP基础知识</a></p><h2 id="1-6-lvs集群和高并发"><a href="#1-6-lvs集群和高并发" class="headerlink" title="1.6 lvs集群和高并发"></a>1.6 lvs集群和高并发</h2><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/107429909">1.6.1 linux和高并发-lvs集群和高并发-lvs中3种模型推导</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/107430010">1.6.2 linux和高并发-lvs集群和高并发-lvs功能配置介绍</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/107437637">1.6.3 linux和高并发-lvs集群和高并发-lvs中DR模型实验</a></p><h2 id="1-7-nginx集群和高并发"><a href="#1-7-nginx集群和高并发" class="headerlink" title="1.7 nginx集群和高并发"></a>1.7 nginx集群和高并发</h2><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/107438297">1.7.1 linux和高并发-nginx集群和高并发-反向代理概念</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/107502326">1.7.2 linux和高并发-nginx集群和高并发-Nginx的安装和配置</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/107735715">1.7.3 linux和高并发-nginx集群和高并发-Nginx反向代理和负载均衡实战</a></p><h2 id="1-8-keepalived和单点故障"><a href="#1-8-keepalived和单点故障" class="headerlink" title="1.8 keepalived和单点故障"></a>1.8 keepalived和单点故障</h2><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/107738273">1.8.1 linux和高并发-keepalived和单点故障-keepalived概念</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/107738370">1.8.2 linux和高并发-keepalived和单点故障-keepalived安装和实验</a></p><hr><h1 id="2-hadoop体系之离线计算"><a href="#2-hadoop体系之离线计算" class="headerlink" title="2.hadoop体系之离线计算"></a>2.hadoop体系之离线计算</h1><h2 id="2-1-hdfs分布式文件系统"><a href="#2-1-hdfs分布式文件系统" class="headerlink" title="2.1 hdfs分布式文件系统"></a>2.1 hdfs分布式文件系统</h2><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/108868942">2.1.0 hadoop体系之离线计算-hdfs分布式文件系统-基本环境配置</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/107748480">2.1.1 hadoop体系之离线计算-hdfs分布式文件系统-hadoop简介</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/108446409">2.1.2 hadoop体系之离线计算-hdfs分布式文件系统-存储模型（hdfs分布式存储系统）</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/108446992">2.1.3 hadoop体系之离线计算-hdfs分布式文件系统-副本机制+node工作机制+HDFS文件读写过程</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/108447456">2.1.4 hadoop体系之离线计算-hdfs分布式文件系统-架构模型</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/108671947">2.1.5 hadoop体系之离线计算-hdfs分布式文件系统-伪分布式安装</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/108719051">2.1.6 hadoop体系之离线计算-hdfs分布式文件系统-全分布式安装</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/108879969">2.1.6 hadoop体系之离线计算-hdfs分布式文件系统-全分布式安装（2）</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109259402">2.1.6 hadoop体系之离线计算-hdfs分布式文件系统-全分布式安装hadoop2.7.7（3）</a></p><p><a href="https://blank.blog.csdn.net/article/details/108882512">2.1.7 hadoop体系之离线计算-hdfs分布式文件系统-hdfs命令行使用和API操作</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/111531926">2.1.8 hadoop体系之离线计算-hdfs分布式文件系统-HA(高可用)-Hadoop集群环境搭建</a></p><p><a href="https://blank.blog.csdn.net/article/details/122417110">2.1.9 hadoop体系之离线计算-hdfs分布式文件系统-Hadoop数据压缩</a></p><h2 id="2-2-mapreduce分布式计算"><a href="#2-2-mapreduce分布式计算" class="headerlink" title="2.2 mapreduce分布式计算"></a>2.2 mapreduce分布式计算</h2><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/108794209">2.2.1 hadoop体系之离线计算-mapreduce分布式计算-mapreduce架构概念</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/108969800">2.2.2 hadoop体系之离线计算-mapreduce分布式计算-WordCount案例</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/108979432">2.2.3 hadoop体系之离线计算-mapreduce分布式计算-MapReduce分区</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/108981098">2.2.4 hadoop体系之离线计算-mapreduce分布式计算-MapReduce序列化和排序</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/108992281">2.2.5 hadoop体系之离线计算-mapreduce分布式计算-MapReduce中的计数器</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/108993246">2.2.6 hadoop体系之离线计算-mapreduce分布式计算-规约Combiner</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/108999857">2.2.7 hadoop体系之离线计算-mapreduce分布式计算-流量统计之统计求和</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109001206">2.2.8 hadoop体系之离线计算-mapreduce分布式计算-流量统计之上行流量倒序排序（递减排序）</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109002673">2.2.9 hadoop体系之离线计算-mapreduce分布式计算-流量统计之手机号码分区</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109003147">2.2.10 hadoop体系之离线计算-mapreduce分布式计算-MapReduce运行机制总结</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109003992">2.2.11 hadoop体系之离线计算-mapreduce分布式计算-案例：Reduce端实现Join</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/110878613">2.2.12 hadoop体系之离线计算-mapreduce分布式计算-hadoop常见问题总结（hdfs+yarn+mapreduce）</a></p><h2 id="2-3-Hive-数据仓库工具"><a href="#2-3-Hive-数据仓库工具" class="headerlink" title="2.3 Hive-数据仓库工具"></a>2.3 Hive-数据仓库工具</h2><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109034269">2.3.1 hadoop体系之离线计算-Hive数据仓库-什么是数据仓库？</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109035022">2.3.2 hadoop体系之离线计算-Hive数据仓库-Hive基本概念和架构分析</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109037027">2.3.3 hadoop体系之离线计算-Hive数据仓库-Hive的安装和交互方式</a></p><p><a href="https://blank.blog.csdn.net/article/details/110825871">2.3.3 hadoop体系之离线计算-Hive数据仓库-Hive的安装和交互方式(2)</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109050159">2.3.4 hadoop体系之离线计算-Hive数据仓库-Hive数据库操作</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109111400">2.3.5 hadoop体系之离线计算-Hive数据仓库-Hive表操作</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109118280">2.3.6 hadoop体系之离线计算-Hive数据仓库-Hive查询语法</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109120126">2.3.7 hadoop体系之离线计算-Hive数据仓库-Hive函数</a></p><p><a href="https://blank.blog.csdn.net/article/details/110878248">2.3.8 hadoop体系之离线计算-Hive数据仓库-Hive常见问题总结</a></p><p><a href="https://blank.blog.csdn.net/article/details/110878983">2.3.9 hadoop体系之离线计算-Hive数据仓库-hql实现wordcount操作</a></p><p><a href="https://blank.blog.csdn.net/article/details/118705221">2.3.10 hadoop体系之离线计算-Hive数据仓库-MaxCompute SQL调优</a></p><p><a href="https://blank.blog.csdn.net/article/details/119191413">2.3.11 hadoop体系之离线计算-Hive数据仓库-MaxCompute SQL多维聚合求PV和UV</a></p><p><a href="https://blank.blog.csdn.net/article/details/123642822?spm=1001.2014.3001.5502">2.3.12 hadoop体系之离线计算-Hive数据仓库-HIVE的严格模式</a></p><h2 id="2-8-Hbase（列存储数据库）-NoSQL数据库"><a href="#2-8-Hbase（列存储数据库）-NoSQL数据库" class="headerlink" title="2.8 Hbase（列存储数据库）-NoSQL数据库"></a>2.8 Hbase（列存储数据库）-NoSQL数据库</h2><p><a href="https://blank.blog.csdn.net/article/details/110351343">2.8.1 hadoop体系之离线计算-HBase数据库-HBase简介</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/110351783">2.8.2 hadoop体系之离线计算-HBase数据库-HBase安装和配置</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/110352043">2.8.3 hadoop体系之离线计算-HBase数据库-HBase Shell操作</a></p><p><a href="https://blank.blog.csdn.net/article/details/110406216">2.8.4 hadoop体系之离线计算-HBase数据库-HBase java_api操作</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/110469281">2.8.5 hadoop体系之离线计算-HBase数据库-HBase高级-详细架构</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/110489198">2.8.6 hadoop体系之离线计算-HBase数据库-HBase高级-HBase写流程</a></p><p><a href="https://blank.blog.csdn.net/article/details/110500839">2.8.7 hadoop体系之离线计算-HBase数据库-HBase高级-HBase-数据Flush过程</a></p><p><a href="https://blank.blog.csdn.net/article/details/110506177">2.8.8 hadoop体系之离线计算-HBase数据库-HBase高级-HBase读流程</a></p><p><a href="https://blank.blog.csdn.net/article/details/110531003">2.8.9 hadoop体系之离线计算-HBase数据库-HBase高级-HBase-StoreFile Compaction合并流程</a></p><p><a href="https://blank.blog.csdn.net/article/details/110533898">2.8.10 hadoop体系之离线计算-HBase数据库-HBase高级-HBase-Region Split拆分</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/110633045">2.8.11 hadoop体系之离线计算-HBase数据库-HBase高级-HBase利用MapReduce</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/110847849">2.8.12 hadoop体系之离线计算-HBase数据库-HBase高级-HBase与Hive交互</a></p><p><a href="https://blank.blog.csdn.net/article/details/110850493">2.8.13 hadoop体系之离线计算-HBase数据库-HBase的优化</a></p><p><a href="https://blank.blog.csdn.net/article/details/110878125">2.8.14 hadoop体系之离线计算-HBase数据库-HBase常见问题总结</a></p><p><a href="https://blank.blog.csdn.net/article/details/110954982">2.8.15 hadoop体系之离线计算-HBase数据库-项目实战：微博</a></p><h2 id="2-4-Zookeeper-分布式服务框架"><a href="#2-4-Zookeeper-分布式服务框架" class="headerlink" title="2.4 Zookeeper-分布式服务框架"></a>2.4 Zookeeper-分布式服务框架</h2><p><a href="https://blank.blog.csdn.net/article/details/108869933">2.4.1 hadoop体系之离线计算-Zookeeper分布式服务框架-初识ZooKeeper</a></p><p><a href="https://blank.blog.csdn.net/article/details/109313501">2.4.2 hadoop体系之离线计算-Zookeeper分布式服务框架-单机环境和集群环境搭建</a></p><p><a href="https://blank.blog.csdn.net/article/details/111355628">2.4.3 hadoop体系之离线计算-Zookeeper分布式服务框架-解释Zookeeper的选举机制</a></p><hr><h1 id="3-spark体系之分布式计算"><a href="#3-spark体系之分布式计算" class="headerlink" title="3.spark体系之分布式计算"></a>3.spark体系之分布式计算</h1><h2 id="3-1-scala分布式计算机开发语言"><a href="#3-1-scala分布式计算机开发语言" class="headerlink" title="3.1 scala分布式计算机开发语言"></a>3.1 scala分布式计算机开发语言</h2><p><a href="https://blank.blog.csdn.net/article/details/109385064">3.1.1 spark体系之分布式计算-scala编程-scala介绍和安装（win+linux）</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109385572">3.1.2 spark体系之分布式计算-scala编程-scala基础</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109403662">3.1.3 spark体系之分布式计算-scala编程-scala函数</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109404012">3.1.4 spark体系之分布式计算-scala编程-scala字符串</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109404080">3.1.5 spark体系之分布式计算-scala编程-scala中的集合（数组array、list、set、map、元组）</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109429952">3.1.6 spark体系之分布式计算-scala编程-scala中trait特性</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109430208">3.1.7 spark体系之分布式计算-scala编程-scala中模式匹配match</a></p><h2 id="3-2-spark-core之离线计算"><a href="#3-2-spark-core之离线计算" class="headerlink" title="3.2 spark-core之离线计算"></a>3.2 spark-core之离线计算</h2><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109202314">3.2.1 spark体系之分布式计算-spark-core之离线计算-初识Spark</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/111239071">3.2.2 spark体系之分布式计算-spark-core之离线计算-Spark-Local模式环境搭建</a></p><p><a href="https://blank.blog.csdn.net/article/details/111239508">3.2.3 spark体系之分布式计算-spark-core之离线计算-Spark-Standalone普通模式+HA模式</a></p><p><a href="https://blank.blog.csdn.net/article/details/109202971">3.2.4 spark体系之分布式计算-spark-core之离线计算-计算WordCount（java版【eclipse】+scala版本【IDEA】）</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/111240773">3.2.5 spark体系之分布式计算-spark-core之离线计算-HA-Spark集群环境搭建(Yarn模式)</a></p><h2 id="3-3-spark-sql"><a href="#3-3-spark-sql" class="headerlink" title="3.3 spark-sql"></a>3.3 spark-sql</h2><h2 id="3-4-spark-stream流式计算"><a href="#3-4-spark-stream流式计算" class="headerlink" title="3.4 spark-stream流式计算"></a>3.4 spark-stream流式计算</h2><h2 id="3-5-STORM流式框架"><a href="#3-5-STORM流式框架" class="headerlink" title="3.5 STORM流式框架"></a>3.5 STORM流式框架</h2><hr><h1 id="4-Flink-流处理框架"><a href="#4-Flink-流处理框架" class="headerlink" title="4.Flink-流处理框架"></a>4.Flink-流处理框架</h1><h2 id="4-1-Flink基础知识"><a href="#4-1-Flink基础知识" class="headerlink" title="4.1 Flink基础知识"></a>4.1 Flink基础知识</h2><p><a href="https://blank.blog.csdn.net/article/details/111873754">4.1.1 Flink-流处理框架-Flink简介</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/111482849">4.1.2 Flink-流处理框架-wordCount的批处理和流处理</a></p><p><a href="https://blank.blog.csdn.net/article/details/111485708">4.1.3 Flink-流处理框架-Flink-Local模式环境搭建</a></p><p><a href="https://blank.blog.csdn.net/article/details/111486473">4.1.4 Flink-流处理框架-Flink集群环境搭建(Standalone模式)</a></p><p><a href="https://blank.blog.csdn.net/article/details/111487332">4.1.5 Flink-流处理框架-HA-Flink集群环境搭建(Standalone模式)</a></p><p><a href="https://blank.blog.csdn.net/article/details/111488208">4.1.6 Flink-流处理框架-HA-Flink集群环境搭建(Yarn模式)</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/111874245">4.1.7 Flink-流处理框架-Flink On Yarn三种部署方式</a></p><p><a href="https://blank.blog.csdn.net/article/details/113789608">4.1.8 Flink-流处理框架-Flink运行架构</a></p><p><a href="https://blank.blog.csdn.net/article/details/113899867">4.1.9 Flink-流处理框架-Flink流处理API之Environment</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/113900862">4.1.10 Flink-流处理框架-Flink流处理API之Source数据源</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/113915951">4.1.11 Flink-流处理框架-Flink流处理API之Transform转换算子</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/113935139">4.1.12 Flink-流处理框架-Flink流处理API之支持的数据类型总结</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/114278028">4.1.13 Flink-流处理框架-</a><a href="https://blog.csdn.net/Suyebiubiu/article/details/113935139">Flink流处理API之</a><a href="https://blog.csdn.net/Suyebiubiu/article/details/114278028">实现 UDF 函数（更细粒度的控制流）</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/114283605">4.1.14 Flink-流处理框架-Flink流处理API之数据重分区操作</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/114284856">4.1.15 Flink-流处理框架-Flink流处理API之sink输出操作</a></p><p><a href="https://blank.blog.csdn.net/article/details/114310786">4.1.16 Flink-流处理框架-Window API之Windows概述</a></p><p><a href="https://blank.blog.csdn.net/article/details/114311357">4.1.17 Flink-流处理框架-Window API之窗口分配器</a></p><p><a href="https://blank.blog.csdn.net/article/details/114317459">4.1.18 Flink-流处理框架-Window API之窗口函数window function</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/114359951">4.1.19 Flink-流处理框架-Flink中的时间语义和watermark水位线</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/114642423">4.1.20 Flink-流处理框架-ProcessFunction API（底层 API）</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/114372022">4.1.21 Flink-流处理框架-Flink中的状态管理之算子状态+键控状态</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/114372455">4.1.22 Flink-流处理框架-Flink中的状态管理之状态编程-温度跳变报警</a></p><p><a href="https://blank.blog.csdn.net/article/details/114631203">4.1.23 Flink-流处理框架-Flink中的状态管理之状态后端</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/114649854">4.1.24 Flink-流处理框架-Flink中的容错机制之状态一致性级别和端到端的状态一致性</a></p><p><a href="https://blank.blog.csdn.net/article/details/114664172">4.1.25 Flink-流处理框架-Flink中的容错机制之Flink+Kafka 端到端状态一致性的保证</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/114650077">4.1.26 Flink-流处理框架-Flink中的容错机制之检查点（checkpoint）</a></p><p><a href="https://blank.blog.csdn.net/article/details/114672877">4.1.27 Flink-流处理框架-检查点恢复+flink检查点算法+保存点</a></p><p><a href="https://blank.blog.csdn.net/article/details/123963603">4.1.28 Flink-流处理框架-Flink使用Lambda表达式引发了泛型擦除问题</a></p><h2 id="4-2-Table-API-和-Flink-SQL"><a href="#4-2-Table-API-和-Flink-SQL" class="headerlink" title="4.2 Table API 和 Flink SQL"></a>4.2 Table API 和 Flink SQL</h2><p><a href="https://blank.blog.csdn.net/article/details/114677871">4.2.1 Flink-流处理框架-Table API 与 SQL-基本概念和简单实例程序</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/114680085">4.2.2 Flink-流处理框架-Table API 与 SQL-基本程序结构（创建表环境+在 Catalog 中注册表）</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/114688317">4.2.3 Flink-流处理框架-Table API 与 SQL-流转表+表转流+创建临时视图（Temporary View）</a></p><p><a href="https://blank.blog.csdn.net/article/details/114685393">4.2.4 Flink-流处理框架-Table API 与 SQL-表的查询</a></p><p><a href="https://blank.blog.csdn.net/article/details/114689262">4.2.5 Flink-流处理框架-Table API 与 SQL-表的输出</a></p><p><a href="https://blank.blog.csdn.net/article/details/114703968">4.2.6 Flink-流处理框架-Table API 与 SQL-查看表的执行计划</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/114778101">4.2.7 Flink-流处理框架-Table API 与 SQL-流处理中的特殊概念之动态表+持续查询</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/114779660">4.2.8 Flink-流处理框架-Table API 与 SQL-流处理中的特殊概念之时间特性</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/114786440">4.2.9 Flink-流处理框架-Table API 与 SQL-流处理中的特殊概念之窗口（Windows）</a></p><p><a href="https://blank.blog.csdn.net/article/details/114831069">4.2.10 Flink-流处理框架-Table API 与 SQL-函数（Functions）之内置函数</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/114840193">4.2.11 Flink-流处理框架-Table API 与 SQL-函数（Functions）之用户自定义函数 UDF</a></p><h2 id="4-3-Flink-CDC数据实时数据同步"><a href="#4-3-Flink-CDC数据实时数据同步" class="headerlink" title="4.3 Flink CDC数据实时数据同步"></a>4.3 Flink CDC数据实时数据同步</h2><p><a href="https://blank.blog.csdn.net/article/details/123532646">4.3.1 Flink-流处理框架-Flink CDC数据实时数据同步-何为CDC？</a></p><p><a href="https://blank.blog.csdn.net/article/details/123532887">4.3.2 Flink-流处理框架-Flink CDC数据实时数据同步-何为Flink CDC？</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/123533358?spm=1001.2014.3001.5501">4.3.3 Flink-流处理框架-Flink CDC数据实时数据同步-Flink CDC实操-DataStream方式</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/123533804?spm=1001.2014.3001.5501">4.3.4 Flink-流处理框架-Flink CDC数据实时数据同步-Flink CDC实操-DataStream方式-自定义反序列化器实现</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/123533458?spm=1001.2014.3001.5501">4.3.5 Flink-流处理框架-Flink CDC数据实时数据同步-Flink CDC实操-FlinkSQL方式</a></p><h1 id="4-4-Flink实践"><a href="#4-4-Flink实践" class="headerlink" title="4.4 Flink实践"></a>4.4 Flink实践</h1><p>4.4.1 </p><hr><h1 id="5-数据库相关"><a href="#5-数据库相关" class="headerlink" title="5.数据库相关"></a>5.数据库相关</h1><h2 id="5-1-NoSQL数据库-Redis（键值key-value）"><a href="#5-1-NoSQL数据库-Redis（键值key-value）" class="headerlink" title="5.1 NoSQL数据库-Redis（键值key-value）"></a>5.1 NoSQL数据库-Redis（键值key-value）</h2><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/112259783">5.1.1 NoSQL数据库-Redis（键值key-value）-NoSQL概述</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/112260345">5.1.2 NoSQL数据库-Redis（键值key-value）-Redis介绍和安装</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/112261121">5.1.3 NoSQL数据库-Redis（键值key-value）-五大数据类型</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/112295931">5.1.4 NoSQL数据库-Redis（键值key-value）-三种特殊数据类型</a></p><p><a href="https://blank.blog.csdn.net/article/details/112332233">5.1.5 NoSQL数据库-Redis（键值key-value）-Redis中的事务操作和监控</a></p><p><a href="https://blank.blog.csdn.net/article/details/112338471">5.1.6 NoSQL数据库-Redis（键值key-value）-基础API之Jedis 详解</a></p><p><a href="https://blank.blog.csdn.net/article/details/112378385">5.1.7 NoSQL数据库-Redis（键值key-value）-SpringBoot整合Redis</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/112465811">5.1.8 NoSQL数据库-Redis（键值key-value）-Redis配置详解</a></p><p><a href="https://blank.blog.csdn.net/article/details/112492421">5.1.9 NoSQL数据库-Redis（键值key-value）-Redis持久化</a></p><p><a href="https://blank.blog.csdn.net/article/details/112563500">5.1.10 NoSQL数据库-Redis（键值key-value）-Redis实现发布订阅</a></p><p><a href="https://blank.blog.csdn.net/article/details/112569196">5.1.11 NoSQL数据库-Redis（键值key-value）-Redis主从复制</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/112800862">5.1.12 NoSQL数据库-Redis（键值key-value）-Redis哨兵模式</a></p><p><a href="https://blank.blog.csdn.net/article/details/112842361">5.1.13 NoSQL数据库-Redis（键值key-value）-Redis缓存穿透、缓存击穿、缓存雪崩</a></p><hr><h1 id="6-消息队列相关"><a href="#6-消息队列相关" class="headerlink" title="6.消息队列相关"></a>6.消息队列相关</h1><h2 id="6-1-kafka分布式消息队列"><a href="#6-1-kafka分布式消息队列" class="headerlink" title="6.1 kafka分布式消息队列"></a>6.1 kafka分布式消息队列</h2><p><a href="https://blank.blog.csdn.net/article/details/111302931">6.1.1 kafka分布式消息队列-Kafka概述</a></p><p><a href="https://blank.blog.csdn.net/article/details/111303138">6.1.2 kafka分布式消息队列-Kafka集群环境搭建和命令行操作</a></p><p><a href="https://blank.blog.csdn.net/article/details/111308357">6.1.3 kafka分布式消息队列-Kafka架构深入</a></p><h1 id="7-数据同步相关"><a href="#7-数据同步相关" class="headerlink" title="7.数据同步相关"></a>7.数据同步相关</h1><h2 id="7-1-Flume-日志收集系统（实时）"><a href="#7-1-Flume-日志收集系统（实时）" class="headerlink" title="7.1 Flume-日志收集系统（实时）"></a>7.1 Flume-日志收集系统（实时）</h2><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109505385">7.1.1 hadoop体系之离线计算-Flume日志收集系统-Flume介绍</a></p><p><a href="https://blank.blog.csdn.net/article/details/111303393">7.1.1(2) hadoop体系之离线计算-Flume日志收集系统-Flume安装及基本使用</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109506002">7.1.2 hadoop体系之离线计算-Flume日志收集系统-Flume实战（Telnet案例）</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109507189">7.1.3 hadoop体系之离线计算-Flume日志收集系统-Flume实战（采集目录+采集日志）</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109511831">7.1.4 hadoop体系之离线计算-Flume日志收集系统-Agent级联</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109512346">7.1.5 hadoop体系之离线计算-Flume日志收集系统-Flume高可用方案</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109513344">7.1.6 hadoop体系之离线计算-Flume日志收集系统-Flume的负载均衡</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/109515111">7.1.7 hadoop体系之离线计算-Flume日志收集系统-Flume案例分析（拦截器）</a></p><h2 id="7-2-DataX-数据同步工具（实时-离线）"><a href="#7-2-DataX-数据同步工具（实时-离线）" class="headerlink" title="7.2 DataX-数据同步工具（实时+离线）"></a>7.2 DataX-数据同步工具（实时+离线）</h2><h2 id="7-3-Sqoop-Hadoop和数据库数据迁移工具（离线）"><a href="#7-3-Sqoop-Hadoop和数据库数据迁移工具（离线）" class="headerlink" title="7.3 Sqoop-Hadoop和数据库数据迁移工具（离线）"></a>7.3 Sqoop-Hadoop和数据库数据迁移工具（离线）</h2><p><a href="https://blank.blog.csdn.net/article/details/110230272">7.3.1 hadoop体系之离线计算-sqoop数据迁移工具-sqoop简介</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/110230562">7.3.2 hadoop体系之离线计算-sqoop数据迁移工具-sqoop安装</a></p><p><a href="https://blog.csdn.net/Suyebiubiu/article/details/110230682">7.3.3 hadoop体系之离线计算-sqoop数据迁移工具-sqoop实战（导入+导出）</a></p><h2 id="7-4-Maxwell-数据库同步工具（实时）"><a href="#7-4-Maxwell-数据库同步工具（实时）" class="headerlink" title="7.4 Maxwell-数据库同步工具（实时）"></a>7.4 Maxwell-数据库同步工具（实时）</h2><h2 id="7-5-Canal-数据库同步工具（实时）"><a href="#7-5-Canal-数据库同步工具（实时）" class="headerlink" title="7.5 Canal-数据库同步工具（实时）"></a>7.5 Canal-数据库同步工具（实时）</h2><h1 id="8-工作流调度相关"><a href="#8-工作流调度相关" class="headerlink" title="8.工作流调度相关"></a>8.工作流调度相关</h1><h2 id="8-1-Azkaban-工作流调度系统"><a href="#8-1-Azkaban-工作流调度系统" class="headerlink" title="8.1 Azkaban-工作流调度系统"></a>8.1 Azkaban-工作流调度系统</h2><p><a href="https://blank.blog.csdn.net/article/details/110194111">8.1.1 hadoop体系之离线计算-Azkaban工作流调度系统-Azkaban介绍</a></p><p><a href="https://blank.blog.csdn.net/article/details/110197217">8.1.2 hadoop体系之离线计算-Azkaban工作流调度系统-Azkaban的安装（单服务模式+双服务模式）</a></p><p><a href="https://blank.blog.csdn.net/article/details/110198907">8.1.3 hadoop体系之离线计算-Azkaban工作流调度系统-Azkaban多例实战</a></p><h2 id="8-2-Oozie-工作流调度"><a href="#8-2-Oozie-工作流调度" class="headerlink" title="8.2 Oozie-工作流调度"></a>8.2 Oozie-工作流调度</h2><h2 id="8-3-DolphinScheduler-工作流任务调度平台"><a href="#8-3-DolphinScheduler-工作流任务调度平台" class="headerlink" title="8.3 DolphinScheduler-工作流任务调度平台"></a>8.3 DolphinScheduler-工作流任务调度平台</h2><h2 id="8-4-Airflow-调度和监控的工作流"><a href="#8-4-Airflow-调度和监控的工作流" class="headerlink" title="8.4 Airflow-调度和监控的工作流"></a>8.4 Airflow-调度和监控的工作流</h2><p><img src="https://img-blog.csdnimg.cn/img_convert/1beea0448037ac0dd767cd6d988c7885.png" alt="未完待续"></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浅谈MaxCompute SQL调优</title>
      <link href="/2021/04/21/qian-tan-maxcompute-sql-diao-you/"/>
      <url>/2021/04/21/qian-tan-maxcompute-sql-diao-you/</url>
      
        <content type="html"><![CDATA[<h1 id="1-写在前面"><a href="#1-写在前面" class="headerlink" title="1.写在前面"></a>1.写在前面</h1><p>​今天跟大家分享的内容是maxcompute的优化内容，希望能够起到抛砖引玉的作用。我将从三个方面开展这次的主题分享，第一个部分是MC和hive的对比；第二部分是调优方法论，主要是想总结一下我们从代码提交到执行结束，都有哪些位置可能会出现问题，一般情况下又是怎么解决的；最后是结合具体案例，对长尾问题的一些思考。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/09c6c3d2fa524dd28bd79de7e200c900~tplv-k3u1fbpfcp-watermark.image" alt="目录"></p><h1 id="2-MaxCompute对比Hive"><a href="#2-MaxCompute对比Hive" class="headerlink" title="2. MaxCompute对比Hive"></a>2. MaxCompute对比Hive</h1><p>​首先，先对其简单做个介绍，MaxCompute主要是应用在批量结构化数据的存储和计算，主要是数据仓库的和大数据的分析建模方向。这个是MaxCompute系统架构，可以看到MaxCompute支持SQL查询计算，MapReduce计算，支持机器学习，和面向迭代的图计算，对外提供三种Java API接口，非常简洁。MaxCompute和Hive一样可以使用SQL、UDF以及MapReduce开发。基于MaxCompute的无服务器的设计思路，用户只需关心业务和数据，不需要关心底层分布式架构及运维。</p><p><img src="https://img-blog.csdnimg.cn/20210713170611410.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1eWViaXViaXU=,size_16,color_FFFFFF,t_70" alt="MaxCompute介绍"></p><p>​对于MaxCompute，可将飞天视为类似于Hadoop的框架，如Hive基于Hadoop，那么可以理解为MaxCompute基于飞天系统。大家都知道hive依赖hdfs进行数据存储，依赖yarn进行资源管理，正好也对应着盘古和伏羲。为什么阿里要去hadoop，做一个自己的系统，我的看法是hadoop开源更新不可控，无法满足快速迭代的业务需求，不如另起炉灶，但是底层架构有很多相似之处。</p><p>​Maxcompute和hive都是有自己的客户端的，另外maxcompute对hive sql也是有兼容的，只需要一行设置即可。下面是他们的数据源和数据格式，阿里肯定支持自家的ots和oss，均支持hdfs。Maxcompute支持手动和自动的调优，hive仅仅支持手动调优。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9c1abfaf78a84042926dd3019c20fd69~tplv-k3u1fbpfcp-watermark.image" alt="MaxCompute对比Hive"></p><p>​找到了一个2016年的数据，100TB数据全排序，maxcompute比竞品要快要便宜。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/730348ad081e4f41aabfba5297a81cfe~tplv-k3u1fbpfcp-watermark.image" alt="MaxCompute性能试验"></p><h1 id="3-调优方法论"><a href="#3-调优方法论" class="headerlink" title="3.调优方法论"></a>3.调优方法论</h1><p>​我们优化一个sql的前提是这个代码能够成功运行，需要知道提交一个任务都需要经历哪几个阶段。一个sql一般我们叫做一个odps作业，在我们提交一个odps作业之后，都会发生哪些动作呢？我们将整个sql的运行分为<strong>预处理、编译、执行和结束</strong>这四个阶段。</p><p>​以上四个阶段只有预处理阶段没有logview产生，而且预处理阶段一般不会出现问题，这个阶段我们不做考虑，其他三个过程，又会因哪些原因发生阻塞呢，根据细分规则，我们接下来看如果我们的作业在这些位置被卡住，将会有哪些表现，并且我们分析是哪些原因导致的，以及可以采取哪些解决方案。</p><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/07d96f99de974e618ae335def46bedc2~tplv-k3u1fbpfcp-watermark.image" alt="SQL执行过程分析"></p><h2 id="3-1-编译阶段"><a href="#3-1-编译阶段" class="headerlink" title="3.1 编译阶段"></a>3.1 编译阶段</h2><p>​首先，编译阶段指的是什么时候呢？指的是已经了产生logview，但还没有执行计划。根据 logview 的子状态（SubStatusHistory）可以进一步细分为调度、优化、生成物理执行计划、数据跨集群复制等子阶段。编译阶段的问题主要表现为在某个子阶段卡住，即作业长时间停留在某一个子阶段。下面将介绍作业停留在每个子阶段的表现以及可能原因和解决方法。</p><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/acbdc3dfbe3d47c6868f6f48009101ae~tplv-k3u1fbpfcp-watermark.image" alt="编译阶段"></p><h3 id="3-1-1-调度阶段"><a href="#3-1-1-调度阶段" class="headerlink" title="3.1.1 调度阶段"></a>3.1.1 调度阶段</h3><p>【特征】子状态为“Waiting for cluster resource”，作业排队等待被编译。</p><p>【该阶段作业卡住的可能原因 1 】计算集群资源紧缺。</p><p>【解决方法】查看计算集群的状态，需要等待计算集群的资源。</p><p>【该阶段作业卡住的可能原因 2 】编译资源池资源不够：可能有人不小心用脚本一次提交太多作业，把编译资源池占满了。如果发现这种情况，要及时找值班同学咨询。</p><h3 id="3-1-2-优化阶段"><a href="#3-1-2-优化阶段" class="headerlink" title="3.1.2 优化阶段"></a>3.1.2 优化阶段</h3><p>【特征】子状态为“SQLTask is optimizing query”，优化器正在优化执行计划。</p><p>【该阶段作业卡住的可能原因】如果执行计划复杂，需要等待较长时间做优化。</p><p>【解决方法】一般可接受的时间是10分钟以内，如果真的太长时间不退出，基本上可以认为是 odps 的 bug</p><h3 id="3-1-3-生成物理执行计划阶段"><a href="#3-1-3-生成物理执行计划阶段" class="headerlink" title="3.1.3 生成物理执行计划阶段"></a>3.1.3 生成物理执行计划阶段</h3><p>【特征】子状态为“SQLTask is generating execution plan”。</p><p>【该阶段作业卡住的可能原因 1 】读取的分区太多。每个分区需要去根据分区信息来决定处理方式，决定 split，并且会写到生成的执行计划中。</p><p>【解决方法】需要好好设计 SQL，减少分区的数量，包括：分区裁剪、筛除不需要读的分区、把大作业拆成小作业。</p><p>【该阶段作业卡住的可能原因 2 】小文件太多。ODPS 会根据文件大小决定 split，小文件多了会导致计算 split 的过程耗时增加。</p><p>【解决方法】避免小文件，可以执行一次 alter table merge smallfiles; 让 odps 把小文件 merge 起来</p><p>【注意】上面提到的“分区太多，小文件太多”不是指几十、几百个。基本都是要上万，上十万才会对生成物理执行计划的时间产生较大影响。</p><h3 id="3-1-4-数据跨集群复制阶段"><a href="#3-1-4-数据跨集群复制阶段" class="headerlink" title="3.1.4 数据跨集群复制阶段"></a>3.1.4 数据跨集群复制阶段</h3><p>【特征】子状态列表里面出现多次“Task rerun”，result 里有错误信息“FAILED: ODPS-0110141:Data version exception”。作业看似失败了，实际还在执行，说明作业正在做数据的跨集群复制。</p><p>【该阶段作业卡住的可能原因 1 】project 刚做集群迁移，往往前一两天有大量需要跨集群复制的作业。</p><p>【解决方法】这种情况是预期中的跨集群复制，需要用户等待。</p><p>【该阶段作业卡住的可能原因 2 】可能是作业提交错集群，或者是中间 project 做过迁移，分区过滤没做好，读取了一些比较老的分区。</p><p>【解决方法】检查作业提交的集群是否正确。过滤掉不必要读取的老分区。</p><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/599706205d4d44f9a9b1f3c0ba3098c0~tplv-k3u1fbpfcp-watermark.image" alt="编译阶段"></p><h2 id="3-2-执行阶段"><a href="#3-2-执行阶段" class="headerlink" title="3.2 执行阶段"></a>3.2 执行阶段</h2><p>​执行阶段一般指的是：logview 的 detail 界面有执行计划（执行计划没有全都绿掉），且作业状态还是 Running。执行阶段卡住或执行时间比预期长的主要原因有等待资源，数据倾斜，UDF 执行低效，数据膨胀等等，下面将具体介绍每种情况的特征和解决思路。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c193c61119854c98b0b1182ca8b7a72a~tplv-k3u1fbpfcp-watermark.image" alt="执行阶段"></p><h3 id="3-2-1-等待资源"><a href="#3-2-1-等待资源" class="headerlink" title="3.2.1 等待资源"></a>3.2.1 等待资源</h3><p>【特征】instance 处于 Ready 状态，或部分 instance 是 Running，部分是 Ready 状态。</p><p>【解决思路】确定排队状态是否正常。可以通过 logview 的排队信息“Queue”看作业在队列的位置，作业有排队是正常的。作业的调度顺序不仅与作业提交时间、优先级有关，还和作业所需内存或CPU资源大小能否被满足有关，因此合理设置作业的参数很重要。</p><h3 id="3-2-2-数据倾斜"><a href="#3-2-2-数据倾斜" class="headerlink" title="3.2.2 数据倾斜"></a>3.2.2 数据倾斜</h3><p>【特征】task 中大多数 instance 都已经结束了，但是有某几个 instance 却迟迟不结束（长尾），这些 instance 运行的慢，可能是因为处理的数据多。</p><p>【解决方法】需要找到造成数据倾斜的具体位置，对症下药，利用 Logveiw2.0 查看任务执行图和 instance 运行情况来定位长尾实例。在确定造成数据倾斜的实例、数据来源等信息后，用户需要针对性的对代码甚至算法做一定的修改。</p><h3 id="3-2-3-UDF执行低效"><a href="#3-2-3-UDF执行低效" class="headerlink" title="3.2.3 UDF执行低效"></a>3.2.3 UDF执行低效</h3><p>​这里的 UDF 泛指各种用户自定义的扩展，包括UDF，UDAF，UDTF，UDJ，UDT等。</p><p>【特征】某个 task 执行效率低，且该 task 中有用户自定义的扩展。甚至是 UDF 的执行超时报错。</p><p>【排查方法】任务报错时，可以在 MaxCompute Studio 中快速通过 DAG 图判断报错的 task 中是否包含 UDF。此外，在 task 的 stdout 日志里，UDF 框架会打印 UDF 输入的记录数、输出记录数、以及处理时间，一般来讲，正常情况 Speed(records/s) 在百万或者十万级别，如果降到万级别，那么基本上就有性能问题了。</p><p>【解决思路】</p><ul><li>检查 UDF 是否有 bug，有时候 bug 是由于某些特定的数据值引起的，比如出现某个值的时候会引起死循环。</li><li>检查 UDF 函数是否与内置函数同名。内置函数是有可能被同名 UDF 覆盖的。有相似功能的内置函数的情况下，尽可能不要使用 UDF。内置函数一般经过验证，实现比较高效，并且内置函数对优化器而言是白盒，能够做更多的优化。</li><li>UDF效率低的原因也可能是内存原因，某些UDF在内存计算、排序的数据量比较大时，会报内存溢出错误；内存不足也会导致gc频率过高。可以尝试调整内存参数解决内存不足的问题。</li></ul><h3 id="3-2-4-数据膨胀"><a href="#3-2-4-数据膨胀" class="headerlink" title="3.2.4 数据膨胀"></a>3.2.4 数据膨胀</h3><p>【特征】task 的输出数据量比输入数据量大很多。比如 1G 的数据经过处理，变成了 1T，在一个 instance 下处理 1T 的数据，运行效率肯定会大大降低。输入输出数据量体现在 Task 的 I/O Record 和 I/O Bytes 这两项。</p><p>【解决思路】</p><ul><li>检查代码是否有 bug；</li><li>JOIN 条件是不是写错了，变成笛卡尔积了；</li><li>检查 Aggregation聚合 引起的数据膨胀。因为大多数 aggregator聚合 是 recursive递归 的，中间结果先做了一层 merge，中间结果不大，而且大多数 aggregator 的计算复杂度比较低，即使数据量不小，也能较快完成。所以通常情况下这些操作问题不大，但是select 中使用 aggregation 按照不同维度做 distinct，每一次 distinct 都会使数据做一次膨胀；使用 Grouping Sets (CUBE and ROLLUP) ，中间数据可能会扩展很多倍。有些操作如 collect_list、median 操作需要把全量中间数据都保留下来，可能会产生问题。</li><li>避免join引起的数据膨胀。比如：两个表 join，左表是人口数据，数据量很大，但是由于并行度足够，效率可观。右表是个维表，记录每种性别对应的一些信息（比如每种性别可能的坏毛病），虽然只有两种性别，但是每种都包含数百行。那么如果直接按照性别来 join，可能会让左表膨胀数百倍。要解决这个问题，可以考虑先将右表的行做聚合，变成两行数据，这样 join 的结果就不会膨胀了。</li></ul><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/233e6b27544b4800888e86dc96266116~tplv-k3u1fbpfcp-watermark.image" alt="执行阶段"></p><h2 id="3-3-结束阶段"><a href="#3-3-结束阶段" class="headerlink" title="3.3 结束阶段"></a>3.3 结束阶段</h2><p>​最后是结束阶段：大部分 SQL 作业在 Fuxi 作业结束后即停止。但有时 Fuxi 作业结束时，作业总体进度仍然处于运行状态。如下图中的 logview，右侧 Job Details 页面显示 Fuxi 作业所有阶段为 Terminated，但左侧代表作业整体进度的 Status 仍然显示 Running，造成这种现象的情况一般分为两种：一个 SQL 作业可能包含多个 Fuxi 作业，比如子查询多阶段执行，作业输出小文件过多导致的自动合并作业；Fuxi 作业结束后，SQL 在结束阶段运行于控制集群的逻辑占用时间较长，比如更新动态分区的元数据。</p><p>​下面将举例介绍几种典型。</p><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7fb6a2cb61ff4a37b160e9f97b3aa843~tplv-k3u1fbpfcp-watermark.image" alt="结束阶段"></p><h3 id="3-3-1-子查询多阶段执行"><a href="#3-3-1-子查询多阶段执行" class="headerlink" title="3.3.1 子查询多阶段执行"></a>3.3.1 子查询多阶段执行</h3><p>​大部分情况下，MaxCompute SQL 的子查询会被编译进同一个 Fuxi DAG，即所有子查询和主查询都通过一个 Fuxi 作业完成。但也有一些特殊子查询需要先将子查询单独执行。</p><pre class="line-numbers language-sql" data-language="sql"><code class="language-sql"><span class="token keyword">SELECT</span> product<span class="token punctuation">,</span> <span class="token function">sum</span><span class="token punctuation">(</span>price<span class="token punctuation">)</span> <span class="token keyword">FROM</span> sales <span class="token keyword">WHERE</span> ds <span class="token operator">in</span> <span class="token punctuation">(</span><span class="token keyword">SELECT</span> <span class="token keyword">DISTINCT</span> ds <span class="token keyword">FROM</span> t_ds_set<span class="token punctuation">)</span> <span class="token keyword">GROUP</span> <span class="token keyword">BY</span> product<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p>​子查询 SELECT DISTINCT ds FROM t_ds_set 先执行，其结果需要被用来做分区裁剪，来优化主查询需要读取的分区数。这两次运行就会产生两个 fuxi 作业。</p><h3 id="3-3-2-过多小文件"><a href="#3-3-2-过多小文件" class="headerlink" title="3.3.2 过多小文件"></a>3.3.2 过多小文件</h3><p>​小文件主要带来存储和计算两方面问题。存储方面，小文件过多会给 Pangu 文件系统带来一定的压力，且影响空间的有效利用；计算方面，ODPS 处理单个大文件比处理多个小文件更有效率，小文件过多会影响整体的计算执行性能。因此，为了避免系统产生过多小文件，SQL 作业在结束时会针对一定条件自动触发合并小文件的操作。小文件的判定，是通过参数 odps.merge.smallfile.filesize.threshold 来设置的，该配置默认为 32MB，小于这个阈值的文件都会被判定为小文件。</p><p>​自动合并小文件多出来的 merge task，虽然会增加当前作业整体执行时间，但是会让结果表在合并后产生的文件数和文件大小更合理，从而避免对文件系统产生过大压力，也使得表被后续的作业使用时，拥有更好的读取性能。如果结果实际不大，但是文件数过多，那么最好是先检查下小文件阈值配置是否正确。</p><h3 id="3-3-3-动态分区元数据更新"><a href="#3-3-3-动态分区元数据更新" class="headerlink" title="3.3.3 动态分区元数据更新"></a>3.3.3 动态分区元数据更新</h3><p>​Fuxi 作业执行完后，有可能还有一些元数据操作。比如要把结果数据挪到特定目录去，然后把表的元数据更新。有可能动态分区输出了太多分区，那么还是可能会消耗一定的时间的。</p><p>​Fuxi 作业执行结束后，仍需要一段时间进行表的元数据更新。</p><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8719c25219694973b259a1aa6375b822~tplv-k3u1fbpfcp-watermark.image" alt="结束阶段"></p><h1 id="4-计算长尾案例分享"><a href="#4-计算长尾案例分享" class="headerlink" title="4.计算长尾案例分享"></a>4.计算长尾案例分享</h1><p>​最后，我们来讨论一些长尾的案例。长尾问题是分布式计算里最常见的问题之一，也是典型的疑难杂症。究其原因，是因为数据分布不均，导致各个节点的工作量不同，整个任务就需要等最慢的节点完成才能完成。我们从长尾现象和原因入手，针对实际业务处理过程中，遇到的长尾现象，分享给大家优化思路和解决方案。</p><p>​正式进入这个主题之前，我们需要知道几个概念。我们提交到maxcompute上的任务都是由1个到n个fuxi job组成的。图中的任务就是由3个fuxi job来完成的，每一个fuxi job是由1个到n个fuxi task组成的。一个fuxi task是由1个到n个fuxi instance完成。复习了这些概念之后，我们进入下面的主题。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ca5ce29083724d94b649e094a7014627~tplv-k3u1fbpfcp-watermark.image" alt="Fuxi概念区分"></p><p>​我们如何查看任务是否发生了长尾？长尾的现象是什么？logview是帮助我们排查这些问题重要的工具和手段，我们一般会逐一点击task，页面下端会显示这个task任务的所有instance的运行情况，有运行时间，起止时间，如果看到红框内有long tails说明发生了长尾。系统是怎么认定发生了长尾呢？是因为这个任务执行完成之后，系统会对每个instance时间做统计，求出一个平均值，一般来说如果某些instance是这个平均时间的两倍以上，就认定发生了长尾现象（logview1.0是三倍），logview2.0异常情况区分了长尾和数据倾斜，两个异常的关注点是不一样，数据倾斜关注的是数据的IO数据量大小，长尾关注的instance的执行时间。</p><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3818f483907443b7b9f6d98a1d808d67~tplv-k3u1fbpfcp-watermark.image" alt="长尾现象"></p><p>​我们看一下为什么会发生长尾呢？我们举一个例子，这个例子就是简单的wordcount实际场景的例子。这个场景下会用到两个task，一个map，一个reduce。我们看一下整个wordcount的流程。</p><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e23e6371443c4c30b8e1556f544a871a~tplv-k3u1fbpfcp-watermark.image" alt="wordCount过程"></p><p>​整个wordcount的流程，输入的数据在起始端的时候会被分片，分片的数据进入map instance以后，map instance会去读每一条记录，然后把key放在第一个参数位置，value会记录上1，下一个阶段是shuffer阶段，shuffer阶段的前一个部分会做一个排序，排序之后还会做一个combiner的操作，combiner阶段会把相同的key的value累加起来，组成一个新的key-value值，在shuffer的后半段，相同key的记录会进入相同的reduce instance上去，reduce阶段会再做一个combiner操作，最后输出数据。我们看一下哪些阶段容易发生长尾问题，首先是map阶段，map阶段有可能发生长尾，但是在实际应用中，这种现象不经常发生，如果发生了，大家可以一块跟踪一下整个问题。下一个容易发生长尾的地方是shuffer dispatch的地方，就是shuffer后期分配reduce的阶段。相同的key会分配到相同的reduce上去处理，如果一个key的数据非常非常多，那这个reduce真的是非常幸运了，他完成的时间可能会比其他的instance要长，这个时候长尾现象就发生了。</p><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/429524a186f744258038a5f031559d75~tplv-k3u1fbpfcp-watermark.image" alt="长尾原因"></p><h2 id="4-1-group-by长尾问题"><a href="#4-1-group-by长尾问题" class="headerlink" title="4.1 group by长尾问题"></a>4.1 group by长尾问题</h2><p>​我们接着看一下我们遇到的长尾的场景，以及怎么做优化？第一个场景就是group by ，比如我们app中某一个商品卖得很好，我们想要计算这个商品的pu，pv/uv，往往会做一个group by的操作。和我们刚才的wordcount例子一样，往往会是一个map+reduce，发生长尾的地方往往是shuffer dispatch的地方。所以如果发生了长尾，我们应该怎么解决呢？我们思考能不能把reduce这个hot key打散，不让他分发到同一个reduce instance。</p><p><img src="https://img-blog.csdnimg.cn/20210713174345545.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1eWViaXViaXU=,size_16,color_FFFFFF,t_70" alt="Group By长尾问题"></p><p>​系统提供了一个参数，这个参数会在shuffer dispatch的时候，算法里面会加入一个随机的因素，会更加均匀的将数据分发到reduce上。大家可以看到对比，在这个参数开启前，dag图是一个map+reduce，开启之后是一个map+两个reduce。这跟我们刚才的想法是一致的，中间的reduce的作用就是将hot key给打散。但是需要注意的是，这个参数仅仅对group by有效，如果长尾现象并不严重，用这种方法增加一次reduce，时间消耗反而更大。</p><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/241a341ea5ee4e17ada44ec6da44e49e~tplv-k3u1fbpfcp-watermark.image" alt="解决方案"></p><h2 id="4-2-Count-Distinct长尾问题"><a href="#4-2-Count-Distinct长尾问题" class="headerlink" title="4.2 Count Distinct长尾问题"></a>4.2 Count Distinct长尾问题</h2><p>​再看另一个场景，count distinct长尾。当我们计算商品购买uv的时候，固定的特殊值比较多，也会发生长尾现象。我们可以不用distinct，用group by来改写。但是我们改写之后由26s变成了33秒。我们初衷是避免使用distinct，使用group by，并且开启了参数。这个实验充分说明如果长尾不是很严重，是否开启这个参数是值得商榷的。那还能怎么做呢？</p><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7605141424b544d2be2ac72aa0aa0da8~tplv-k3u1fbpfcp-watermark.image" alt="Count Distinct长尾问题"></p><p>​我们可以使用where 先把这个特殊值（比如null）给过滤掉，我们count完了之后再加1就好了，所以这些优化是需要根据用户具体的数据结构、类型规模来决定。</p><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4cdc51da9a7645c89b37be145fcea4c1~tplv-k3u1fbpfcp-watermark.image" alt="解决方案"></p><h2 id="4-3-动态分区长尾问题"><a href="#4-3-动态分区长尾问题" class="headerlink" title="4.3 动态分区长尾问题"></a>4.3 动态分区长尾问题</h2><p>​下一个场景是动态分区，在动态分区的场景里面，非常有可能发生长尾。上面是一个动态分区写入的一个语句，假如我们有n个map instance，我们的目标分区有m个，可能会产生n*m个小文件。大家都知道小文件过多会给我们后续查询带来很多的问题，所以系统针对这种情况是做了优化的，会尽可能避免产生过多的小文件。我们看一下执行计划，下面红框中有两个值，第一个是我们的分区，第二个值具体是0-10之间的一个数，系统为了避免小文件产生，做了一个reshuffer。reshuffer具体做了什么呢？会在shuffer dispatch的时候，相同目标分区的数据，会由最多10个reduce来处理，实际上减少了reduce的个数，也减少了小文件的产生。</p><p><img src="https://img-blog.csdnimg.cn/20210713174708726.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1eWViaXViaXU=,size_16,color_FFFFFF,t_70" alt="动态分区长尾问题"></p><p>​但是这个任务花费了3分钟，并且发生了长尾现象。我们想既可以避免小文件产生，又不想发生长尾，可以怎么做呢？</p><p><img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ccc8fe64797448c0a4a0deed8d0be4f1~tplv-k3u1fbpfcp-watermark.image" alt="长尾问题"></p><p>​手动的把reshuffer开关给关掉（这个开关默认是打开的）。任务在10s左右就跑完了，效果还是很明显的。所以如果目标分区不多，建议先关闭reshuttle;任务执行完毕后，手动执行MergeTask，减少小文件。这个方法比较折中，大家可以尝试一下。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6cc391258d5440e8a1e94f00b89a337f~tplv-k3u1fbpfcp-watermark.image" alt="解决方案"></p><h2 id="4-4-Join长尾问题"><a href="#4-4-Join长尾问题" class="headerlink" title="4.4 Join长尾问题"></a>4.4 Join长尾问题</h2><p>​join长尾，join长尾还是相当普遍的，每个join也会被解释器解释成一个mr任务，map端读取join两边表，reduce做join操作，没有办法避免shuffer dispatch的时候产生的hot key的问题。 </p><p><img src="https://img-blog.csdnimg.cn/20210713174847340.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1N1eWViaXViaXU=,size_16,color_FFFFFF,t_70" alt="Join长尾问题"></p><p>​很多人会建议用mapjoin，mapjoin的原理是将join的操作由reduce阶段移到map端去做，会把小表放到每一个map instance上面，每一个map instance都拥有小表所有的内容，可以在map本地进行join。但是可想而知，如果一个map instance能存下小表所有内容，单机内存要求还是非常高的。所以一般会有这个限制，mapjoin的小表占用的内存总和不得超过512MB。   </p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a4adff6bfc054834b6b09fb50eeea6bf~tplv-k3u1fbpfcp-watermark.image" alt="解决方案一"></p><p>​但是我们实际使用场景中，表的大小超过512，还是非常常见的。很多人会说我两边数据都很大，没有办法使用mapjoin。那应该怎么办呢，我们可以尝试使用分而治之的方法解决。长尾的问题就是热点key太多，发送到一个reduce instance，导致运行时间过长，我们可以把热点key找出来，或者找到一个范围。将热点key和非热点key分开处理。</p><ul><li>（1）第一步我们可以先做个group by和order by找出热点item，并且把这些信息放到一个临时表中。</li><li>（2）找到这些热点key之后，可以将热点key先关联，一般来说数据不会很多，我们能用上mapjoin就尽量用上mapjoin，能整个提高第二步骤的执行效率。</li><li>（3）第三步将非常用item取出关联</li><li>（4）最后将两个部分union all合并，而且上面很多过程都是可以并行执行，所以分享给大家。</li></ul><p><img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e9df8e6f80794bb79d1048331d3c1d4f~tplv-k3u1fbpfcp-watermark.image" alt="解决方案二"></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MaxCompute SQL </tag>
            
            <tag> SQL优化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/09/07/hello-world/"/>
      <url>/2020/09/07/hello-world/</url>
      
        <content type="html"><![CDATA[<h1 id="测试数据"><a href="#测试数据" class="headerlink" title="测试数据"></a>测试数据</h1><p>测试一下</p>]]></content>
      
      
      <categories>
          
          <category> Markdown </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Markdown </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
